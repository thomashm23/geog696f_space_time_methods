{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis II\n",
    "\n",
    "In this notebook we are going to be reviewing techniques for modeling time series based on fitting autoregressive and moving average components to the original data. ARMA (Autoregressive Moving Average) and ARIMA (Autoregressive Integrated Moving Average) methods are quite often used for forecasting or predicting the future temporal behavior of a system based on prior observations of that system.  As you'll see, ARIMA models don't require any additional or external predictors to model the time series - all that is needed is the time series itself and the ability to estimate parameters of coefficients that describe its behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Modeling \n",
    "\n",
    "As we will discuss in lecture, ARMA and ARIMA modeling attempt to capture persistence (autocorrelation) and shocks (moving average) components of the time series.  ARIMA adds a third 'Integrated' component related to differencing or trends.  \n",
    "\n",
    "Let's start by looking at some models of the Mauna Loa CO2 record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# you can omit the line below if you'd like, but I really don't like the default fonts in Python, so I switch to Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we'll read in the CO2 data into a Pandas DataFrame and create a datetime index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the CO2 data from the csv file\n",
    "df = pd.read_csv('co2_mm_mlo.csv')\n",
    "\n",
    "# combine 'year' and 'month' into a single new datetime column called 'date'\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))  # required to have 'day=1' here, which makes it a proper datetime value \n",
    "\n",
    "# now set the 'date' column as the index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# now we can drop the columns that we aren't going to use - note you need to specify 'axis' for this drop operation\n",
    "df.drop(['year', 'month'], axis=1, inplace=True) \n",
    "\n",
    "# and let's visualize our data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['co2'],'k')\n",
    "plt.xlabel('YEAR')\n",
    "plt.ylabel('CO2 (ppm)')\n",
    "plt.title('Mauna Loa Atmospheric CO2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to fit an ARIMA model to the CO2 data.  First we'll get the ARIMA model from statsmodels.  We'll then specify the model parameters, create the model, fit the model, and compare the fitted values to the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "# ignore warning messages (about data frequency) from statsmodels for now - this isn't a problem for now\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# break out the CO2 column into a Pandas series\n",
    "co2 = df['co2']\n",
    "\n",
    "# declare the model order for each element\n",
    "p = 1 # Autoregressive model component will be order 1\n",
    "d = 1 # First differencing will be used\n",
    "q = 1 # Moving average component of order 1 will be used\n",
    "\n",
    "# create the ARIMA model\n",
    "arima = ARIMA(co2, order = (p,d,q))\n",
    "\n",
    "# fit the ARIMA model\n",
    "arima_model_fit = arima.fit()\n",
    "\n",
    "# get the fitted values from the model so we can compare to our data\n",
    "co2_fitted_values = arima_model_fit.fittedvalues\n",
    "\n",
    "# the ARMA model will be missing the first p values in the fitted values, so we make them a NaN (statsmodels makes them a zero, which is annoying and not helpful!)\n",
    "co2_fitted_values.iloc[:p] = np.nan  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model fitted values and the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(co2, color=\"k\",label=\"Observed CO2 Data\")\n",
    "plt.plot(co2_fitted_values, label=\"Fitted Model Values\", color='red',linestyle=':')\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Original CO2 Data and ARIMA Fitted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  That's pretty impressive!  With an apparently simple and low-order model, we've recreated quite well the CO2 curve, including its trend and seasonal components!  \n",
    "\n",
    "Let's look quickly at the residuals from the model fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals (difference between actual and fitted values)\n",
    "model_residuals = co2 - co2_fitted_values\n",
    "\n",
    "# Plot residuals as a scatter plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(co2.index, model_residuals, label=\"Residuals\", color='lightblue')\n",
    "plt.axhline(y=0, color='red')  # Add a horizontal line at y=0 for reference\n",
    "plt.title(\"Residuals of ARIMA Model\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is encouraging! The residuals are relatively small and show no trends or structure in time that would make us think the model fit was biased.  So far so good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model Selection\n",
    "\n",
    "Above we applied a first order constraint to the 3 model parameters.  But what if we don't know what the best model parameters might be?  This is a very common question in any time of modeling, including regression which we discussed previously. \n",
    "\n",
    "One approach is to try and fit lots and lots of model variants to the data and then compare their relative accuracy.  For this, we'll need to do a few things.  First, we'll decide on a range of possible model parameters (here we'll allow 0, 1, or 2 for each of the three parameters).  Next, we'll use the Python library `itertools` to create a list of all possible model parameter combinations.  Once we've done this, we can loop repeatedly and try different combinations of model parameters.  \n",
    "\n",
    "How will we decide what is a best set of model parameters?  Here we can compare the AIC for each model, with the smallest AIC suggesting a balance between model complexity and model accuracy.  As we loop through and fit each model parameter set, we'll record the AIC and once we're done use it to select the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the itertools functions, which allows us to create all possible combinations of variables - see here: https://docs.python.org/3/library/itertools.html\n",
    "import itertools \n",
    "\n",
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = range(0, 3) # allow 0, 1, 2 as the autogressive model order\n",
    "d = range(0, 3) # allow 0, 1, 2 as the integrated (difference) model order\n",
    "q = range(0, 3) # allow 0, 1, 2 as the moving average model order \n",
    "\n",
    "# Generate all the possible different combinations of p, d and q using the itertools.product function\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "best_aic = np.inf # why infinity here? Because we are going to evaluate every model vs. the best model thus far (the smallest AIC), so the FIRST value of AIC has to be very large for the comparison \n",
    "best_pdq = None # this can be empty\n",
    "\n",
    "# Create a list to store (parameters and AIC) values\n",
    "aic_values = []\n",
    "\n",
    "# Iterate over each combination of p, d, and q contained in the list pdq:\n",
    "for param in pdq: # loop through all the possible model parameter sets we created\n",
    "    \n",
    "    # Create an ARIMA model with the current combination of parameters\n",
    "    model = ARIMA(co2, order=param)\n",
    "    \n",
    "    # Fit the model\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Save the current parameters and AIC score\n",
    "    aic_values.append([param[0], param[1], param[2], results.aic])\n",
    "    \n",
    "    # Uncomment this if you'd like to see the AIC score for the current model as we go through the loop - good for debugging! \n",
    "    # print(\"ARIMA{}: AIC={}\".format(param, results.aic))\n",
    "    \n",
    "    # Check if the current model has the best (now lowest) AIC score, and if so replace the current 'best' pdq and AIC with it\n",
    "    if results.aic < best_aic:\n",
    "        best_aic = results.aic\n",
    "        best_pdq = param\n",
    "\n",
    "  \n",
    "# convert the list of AIC values to a Pandas DataFrame for easier viewing\n",
    "model_df = pd.DataFrame(aic_values, columns=['p', 'd', 'q', 'AIC']) # this now has all our parameters and AIC scores \n",
    "\n",
    "# print the DataFrame \n",
    "print(model_df)\n",
    "\n",
    "# Then print the best model and its AIC score so we know which model was best\n",
    "print(\"Best ARIMA model{} with AIC = {}\".format(best_pdq, best_aic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many of the models with zero order parameters are poor (perhaps not surprisingly).  These scores might be easier to see if we plot them. Let's make a nice plot of AIC scores and model parameters to look at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the DataFrame to hold the (p, d, q) as a single string for labeling our x-axis\n",
    "model_df['label'] = model_df.apply(lambda row: f\"({int(row['p'])},{int(row['d'])},{int(row['q'])})\", axis=1)\n",
    "\n",
    "# Find the index of the best model using direct comparison to best_pdq tuple\n",
    "best_index = model_df[(model_df['p'] == best_pdq[0]) & \n",
    "                      (model_df['d'] == best_pdq[1]) & \n",
    "                      (model_df['q'] == best_pdq[2])].index[0]\n",
    "\n",
    "# make the plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(model_df['label'], model_df['AIC'], marker='o', linestyle='', color='b',label=\"All Models\")\n",
    "plt.plot(best_index, best_aic, marker='*', color='r', markersize=15, linestyle='', label=\"Best Model\")\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45) # Rotate x-axis labels so we can see them all\n",
    "plt.xlabel('Model Order (p, d, q)')\n",
    "plt.ylabel('AIC')\n",
    "plt.title('AIC as a Function of ARIMA Model Order')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations:  Models with zero order parameters (which eliminate that component of the ARIMA model!) do poorly.  But there is a wide variety of model parameter sets that produce similar good (low) scores.  The best model has the lowest AIC, but we can see plenty of other combination that are close and would give similar results. \n",
    "\n",
    "Let's look at some residuals for our simple (1,1,1) model above and our 'best' model from the model fitting exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ARIMA(co2, order=best_pdq)\n",
    "best_model_fit = best_model.fit()\n",
    "\n",
    "# calculate residuals \n",
    "best_model_residuals = co2 - best_model_fit.fittedvalues\n",
    "\n",
    "# the ARIMA model will be missing the first p values in the fitted values, so we make them a NaN \n",
    "best_model_residuals.iloc[:best_pdq[0]] = np.nan  \n",
    "\n",
    "# Create the residual plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(co2.index,best_model_residuals, label='Best Model (2,1,1) Residuals', color='lightblue')\n",
    "plt.scatter(co2.index, model_residuals, label=\"Simple Model (1,1,1) Residuals\", color='blue')\n",
    "\n",
    "plt.axhline(y=0, color='red', linestyle='-') \n",
    "plt.title(f'Residuals of ARIMA{best_pdq} Model')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model selection produced a slightly better model in terms of residuals, particularly for the negative residuals.  Some there was some benefit from the model selection exercise and the discovery of a better model parameter set, but the difference is relatively small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that ARIMA is often used for time series prediction.  Let's see how this is done. \n",
    "\n",
    "First, we're going to bring in a function for scikit-leanr called `train_test_split` (see more [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). This function provides an elegant way to divide up our data into training and testing subsets.  We can use this to evaluate our model's ability to make good predictors or forecasts. \n",
    "\n",
    "Let's do it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ignore warning messages from statsmodels (about data frequency in this case)\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# break out the CO2 column into a new Pandas series\n",
    "co2 = df['co2']\n",
    "\n",
    "# here we pre-define the size of the test set - here I'm making it ~20% of the total data and an integer\n",
    "test_size = int(len(co2) * 0.2)\n",
    "\n",
    "# split data into training and testing sets based on the size we determined above\n",
    "train_data, test_data = train_test_split(co2, test_size=0.2, shuffle=False)\n",
    "\n",
    "# declare the ARIMA model order from our 'best model' above\n",
    "p = 2 # Autoregressive order\n",
    "d = 1 # Differencing order\n",
    "q = 1 # Moving average order\n",
    "\n",
    "# Fit the ARIMA model on the training data now only\n",
    "arima = ARIMA(train_data, order=(p, d, q))\n",
    "arima_model_fit = arima.fit()\n",
    "\n",
    "# forecast values for the withheld test set\n",
    "forecasted_values = arima_model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# get the fitted values from the training data fit\n",
    "co2_fitted_values = arima_model_fit.fittedvalues\n",
    "\n",
    "# fill the first `p` values with NaN as before\n",
    "co2_fitted_values.iloc[:p] = np.nan  \n",
    "\n",
    "# Now plot the training data, the test data, and the forecasted values for the test data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot observed training data\n",
    "plt.plot(train_data, color=\"blue\", label=\"Training Data\")\n",
    "\n",
    "# Plot observed test data\n",
    "plt.plot(test_data.index, test_data, color=\"blue\", linestyle='--',label=\"Test Data\")\n",
    "\n",
    "# Plot fitted values (for training data)\n",
    "plt.plot(co2_fitted_values, label=\"Fitted Model Values (Train)\", color='red', linestyle=':')\n",
    "\n",
    "# Plot forecasted values (for the test data)\n",
    "plt.plot(test_data.index, forecasted_values, label=\"Forecasted Values (Test)\", color='red', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ARIMA Model: Training, Test, and Forecasted Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ack! What happened?  It looks like once the training period was over, the model just contininued the mean value at that point throughout the testing data period!  What happened, do you think? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about a different model? SARIMA to the rescue! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem above is that while the differencing parameter can handle the trend and seasonality when fit to the entire data, it doesn't have enough information in the ARIMA model for the behavior during the forecast period.  We need to give our model more information, in this case about the seasonal cycle!  For this we can use a model called [SARIMA](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html) or (SARIMAX Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors). \n",
    "\n",
    "We'll get SARIMAX from statsmodels again.  Now we need to specify another set of parameters, including the period of seasonality (12 months in this case):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Assuming co2 is your time series data\n",
    "co2 = df['co2']\n",
    "\n",
    "# Split the data into training and testing sets using train_test_split\n",
    "train_data, test_data = train_test_split(co2, test_size=0.2, shuffle=False)\n",
    "\n",
    "# define SARIMA model order (p, d, q) for the NON-seasonal part \n",
    "p = 2  # Non-seasonal autoregressive order\n",
    "d = 1  # Non-seasonal differencing order\n",
    "q = 1  # Non-seasonal moving average order\n",
    "\n",
    "# now the parameters of the seasonal component model (P, D, Q, s), where s is now the length of the seasonal cycle (so, 12 for monthly data with an annual cycle)\n",
    "P = 1  # Seasonal Autoregressive model order\n",
    "D = 1  # Seasonal Differencing model order\n",
    "Q = 1  # Seasonal Moving average model order\n",
    "s = 12  # Seasonal period (monthly data, so we'll use 12)\n",
    "\n",
    "# Fit the SARIMA model on the training data\n",
    "sarima = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n",
    "sarima_model_fit = sarima.fit(disp=0) # note here that adding disp=0 will suppress the model's verbose output, remove if you want the iterative output printed to screen\n",
    "\n",
    "# Forecast values for the test set\n",
    "forecasted_values = sarima_model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Get the fitted values from the training data\n",
    "co2_fitted_values = sarima_model_fit.fittedvalues\n",
    "\n",
    "# Set the first few values (e.g., first 12 months) to NaN\n",
    "num_initial_values_to_remove = 24  # You can choose an appropriate number based on your model\n",
    "co2_fitted_values.iloc[:num_initial_values_to_remove] = np.nan\n",
    "\n",
    "# Plot the training data, test data, fitted values, and forecasted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot observed training data\n",
    "plt.plot(train_data, color=\"blue\", label=\"Training Data\")\n",
    "\n",
    "# Plot observed test data\n",
    "plt.plot(test_data.index, test_data, color=\"blue\", linestyle=\"--\",label=\"Test Data\")\n",
    "\n",
    "# Plot fitted values (for training data)\n",
    "plt.plot(co2_fitted_values, label=\"Fitted Model Values (Train)\", color='red', linestyle=':')\n",
    "\n",
    "# Plot forecasted values (for the test data)\n",
    "plt.plot(test_data.index, forecasted_values, label=\"Forecasted Values (Test)\", color='red', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"SARIMA Model: Training, Test, and Forecasted Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm.  Better, but you can see the forecast doesn't keep up with the rising trend during the test period. \n",
    "\n",
    "We can try adding additional parameters to the SARIMA model.  For instance, here let's specify `trend='t'` in the SARIMAX model to indicate a (linear) trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Assuming co2 is your time series data\n",
    "co2 = df['co2']\n",
    "\n",
    "# Split the data into training and testing sets using train_test_split\n",
    "train_data, test_data = train_test_split(co2, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Define SARIMA model order (p, d, q) for non-seasonal part and (P, D, Q, s) for seasonal part\n",
    "p = 2  # Non-seasonal autoregressive order\n",
    "d = 1  # Non-seasonal differencing order\n",
    "q = 1  # Non-seasonal moving average order\n",
    "\n",
    "# Seasonal component model order: (P, D, Q, s) where s is the length of the seasonal cycle (e.g., 12 for monthly data with yearly seasonality)\n",
    "P = 1  # Autoregressive model order\n",
    "D = 1  # Differencing model order\n",
    "Q = 1  # Moving average model order\n",
    "s = 12  # Seasonal period (monthly data, so we'll use 12)\n",
    "\n",
    "# Fit the SARIMA model on the training data\n",
    "sarima = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s), trend='t') # options for trend are 'c' for constant, 't' for linear, and 'ct' for quadratic \n",
    "sarima_model_fit = sarima.fit(disp=0) # note that adding disp=0 will suppress the model's verbose output\n",
    "\n",
    "# Forecast values for the test set\n",
    "forecasted_values = sarima_model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Get the fitted values from the training data\n",
    "co2_fitted_values = sarima_model_fit.fittedvalues\n",
    "\n",
    "# Set the first few values (e.g., first 12 months) to NaN\n",
    "num_initial_values_to_remove = 24  # You can choose an appropriate number based on your model\n",
    "co2_fitted_values.iloc[:num_initial_values_to_remove] = np.nan\n",
    "\n",
    "# Plot the training data, test data, fitted values, and forecasted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot observed training data\n",
    "plt.plot(train_data, color=\"blue\", label=\"Training Data\")\n",
    "\n",
    "# Plot observed test data\n",
    "plt.plot(test_data.index, test_data, color=\"blue\", linestyle=\"--\",label=\"Test Data\")\n",
    "\n",
    "# Plot fitted values (for training data)\n",
    "plt.plot(co2_fitted_values, label=\"Fitted Model Values (Train)\", color='red', linestyle=':')\n",
    "\n",
    "# Plot forecasted values (for the test data)\n",
    "plt.plot(test_data.index, forecasted_values, label=\"Forecasted Values (Test)\", color='red', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"SARIMA Model: Training, Test, and Forecasted Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, better, but still not quite right.  Why do you think the fit still isn't perfect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Play with the components of the SARIMAX model - is it possible to get a better fit to the trend during the test period? \n",
    "2. Write a model selection loop for the SARIMAX model - what is the optimal model fit based on your evaluation of the AIC? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
