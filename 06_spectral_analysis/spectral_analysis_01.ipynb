{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spectral Analysis I\n",
    "\n",
    "The purpose of spectral analysis of time series is to decompose the temporal behavior into a set of waves or cycles with characteristic lengths (or frequencies) and estimate the variance that they contribute to the total variance of the time series.  This allows us to identify cyclical components from observations that may provide insight into underlying causality or form the basis for predictability and forecasting.  Spectral analysis methods are primarily concerned with moving temporal data (attached to the dimension of time) into frequecny space (attached to the dimension that is the frequency of wavelength of the cycles we identify) while making various trade-offs that are necesaary because of the finite and noisy nature of our time series observations. \n",
    "\n",
    "As with the other topics in this class, one could teach an entire course simply on spectral analysis methods, applications, and cautions.  This and the following notebooks will provide a brief introduction to a few of the methods and some of the things you should look out for when doing your own spectral analysis.  Here are a few additional resources:\n",
    "\n",
    "- Stoica and Moses's [_Spectral Analysis of Signals_](https://www.maths.lu.se/fileadmin/maths/personal_staff/Andreas_Jakobsson/StoicaM05.pdf)\n",
    "- [Spectral Analysis of Paleoclimate Data](https://comptools.climatematch.io/tutorials/W1D4_Paleoclimate/student/W1D4_Tutorial6.html)\n",
    "- [Spectral Analysis with Pyleoclim](https://linked.earth/PyleoTutorials/notebooks/L2_spectral_analysis.html)\n",
    "- Scipy's [signal module for spectral analysis](https://docs.scipy.org/doc/scipy/reference/signal.html#spectral-analysis)\n",
    "\n",
    "As we begin, this quote from [Muller and MacDonald's 2002 book on astronomical causes of the ice ages](https://link.springer.com/book/9783540437796) is useful to keep in mind:\n",
    "\n",
    "> Although there are many ways to do an incorrect spectral analysis, there is no \"correct way” … Be aware that all approaches to spectral analysis entail assumptions, and that the differences in these assumptions often account for the different results of the analyses. If you know what those assumptions are, you can make a reasoned judgement of what conclusions you should draw.\n",
    "\n",
    "Let's get our libraries.  Modules for spectral analysis are in various libraries across the Python ecosystem, but we'll focus mostly on those in Scipy and Numpy for now.  In the next class we'll introduce the Multitaper method (MTM), and make use of some different libraries for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import pandas as pd \n",
    "\n",
    " # gets the signal processing capability of SciPy\n",
    "from scipy import signal\n",
    "\n",
    "# statsmodels has a simple Autocorrelation function we can use for a demonstration of the link between cycles and autocorrelation \n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Matplotlib plotting functionality as well as a helper for axes formatting\n",
    "import matplotlib.pyplot as plt # this line pulls out just the part of matplotlib for creating plots, for simplicity\n",
    "from matplotlib.ticker import ScalarFormatter # this will help us change the axes a bit easier\n",
    "\n",
    "# you can omit the line below if you'd like, but I really don't like the default fonts in Python, so I switch to Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# ignore some warnings for lecture, but recommend YOU only do this once you know what those warnings are! \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a simple periodic time series -- a sine wave.  The code in the block below does that for you.  Try and change the variable `cycles_per_time` to some different values, and observe how the periodic series changes.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(1999)\n",
    "\n",
    "# we'll use 128 time points again\n",
    "n_samples = 128\n",
    "\n",
    "# Create our time vector - e.g. 128 years long\n",
    "t = np.arange(1, n_samples+1)\n",
    "\n",
    "# Create a sine wave with frequency set to the variable cycles_per_time -- you can vary this - try 1, 2, 3, 4, or 5 here\n",
    "cycles_per_time = 2\n",
    "cycle_amplitude = 3 # change this to change the amplitude - power or variance - of the cyclical time series\n",
    "u = 2 * np.pi * (cycles_per_time/128) * t\n",
    "st = cycle_amplitude * np.sin(u)\n",
    "    \n",
    "# Plot the sine wave and observe how many cycles are completed per 128 'years'\n",
    "plt.figure()\n",
    "plt.plot(t, st, 'r', label='sin')\n",
    "plt.xlabel('Years')\n",
    "plt.xlim([1, 128])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some noise to this time series and plot again.  You can change the amplitude of the noise using variable `noise_amplitude` in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a time series that is the sum of the sine wave above and some Gaussian noise with an amplitude of 'noise_amplitude' - you can see how this amplitude affects the spectrum below\n",
    "noise_amplitude = 5\n",
    "my_series = st + (noise_amplitude * np.random.randn(len(t))) # reproducible with random seed above\n",
    "\n",
    "# Plot sum of signals\n",
    "plt.figure()\n",
    "plt.plot(t, st, 'k', label='Signal')\n",
    "plt.plot(t, my_series, 'r-', label='Signal with noise')\n",
    "plt.xlim([1, 128])\n",
    "plt.xlabel('TIME')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth thinking about how the presence of cycles in the data is connected to autocorrelation (which we've discussed in the context of both correlation and time series analysis).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 40  # Number of lags for the autocorrelation \n",
    "autocorr0 = acf(my_series, nlags=lags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the autocorrelation function for the pure cycle (and the cycle+noise case if we'd like).  The presense of a cycle creates long-lag autocorrelation in a time series, since every value is strongly related to the previous value in the series by the cyclical structure created by the sine function.  We'll leverage this self-similarity later when we look at alternative approaches to spectral analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the autocorrelation function for the pure cycle\n",
    "plt.stem(np.arange(lags + 1), autocorr0)\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.xticks(np.arange(0, lags + 1, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use one of the simplest methods for moving from temporal space to frequency space and measuring the relative contribution of cyclical components with different wavelenghts: the periodogram.  While it has fallen out of favor for spectral analysis (it is considered a 'inconsistent estimator' of the population spectrum), but it is a good place to start and often can still be used to provide insights -- albiet sometimes rough estimates -- of the spectrum of the time series. \n",
    "\n",
    "We'll use Scipy's `periodogram` for this.  You can find more details [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the periodogram function from Scipy's signal module\n",
    "from scipy.signal import periodogram \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `periodogram` function accepts our data (arrays, DataSeries, etc.), as well as a number of options. One things we can do is pass the function our choice of [windows](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.get_window.html#scipy.signal.get_window) that can improve the spectral estimates (we'll talk about this in class).  We can also set the length of the Fast Fourier Transform (FFT) used with `nfft=`.  We can also chose the scaling (the units used for the y-axis, the 'power spectral density').  It is often good practice to detrend series before spectral analysis, and this can be done automatically with the `detrend=` command (see [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.detrend.html#scipy.signal.detrend) for options).  We're going to calculate the periodogram for both the cycle itself and the cycle+noise time series we created so we can compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the periodogram including a Hamming window - you can select other windows if you'd like to see the differences: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.get_window.html#scipy.signal.get_window\n",
    "window = \"hamming\"\n",
    "nfft = 2**math.ceil(math.log2(np.size(my_series)))\n",
    "\n",
    "# calculate the periodogram for both the known cycle and the cycle+noise case\n",
    "f, Pxx = periodogram(my_series, window=window, nfft=nfft,scaling='spectrum')\n",
    "f0, Pxx0 = periodogram(st, window=window, nfft=nfft,scaling='spectrum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy returns a value at the 0th frequency, which is difficult to properly interpret and will give a divide-by-zero error when we convert from frequency units (cycles per time) to period units (time per cycle). We'll remove the 0th frequency and the associated power sprectral density estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid division by zero by removing first values from frequency and the spectrum\n",
    "f = f[1:]  # remove zero frequency\n",
    "Pxx = Pxx[1:] # remove corresponding power spectral density estimate\n",
    "Pxx0 = Pxx0[1:] # remove corresponding power spectral density estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can often be easier to think about periods (or wavelengths, the number of years long a cycle is, for instance) than frequency (the number of cycles per time), and this is a simple conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frequency to period (from cycles/year to years/cycle) \n",
    "periods = 1 / f  # divide 1 by the frequency array to get a period array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, let's plot our spectra.   I'm highlight a few of the periods you might expect to see for different `cycles_per_year` from the code above (e.g. 1, 2, 3, 4, or 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the periodogram with period (the years per cycle) on the x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(periods, Pxx,'r',label=\"Cycle + Noise\")  # Exclude the first point to avoid the division by zero problem (zero-frequency)\n",
    "plt.plot(periods, Pxx0,'b',label=\"Cycle Only\")  # Exclude the first point to avoid the division by zero problem (zero-frequency)\n",
    "\n",
    "# Create some lines and labels the specific periods of interest given our 128 year time period\n",
    "important_periods = [128, 64, 42, 32, 26] # various 'cycles per time' possibilities matching the above\n",
    "for period in important_periods:\n",
    "    plt.axvline(x=period, color='lightblue', linestyle='--', alpha=0.75)\n",
    "    plt.text(period, max(Pxx)*0.8, f'{period} years', color='lightblue', rotation=-75, verticalalignment='center')\n",
    "\n",
    "plt.xscale('log') # in this case, you could also use 'linear' here if you wanted\n",
    "plt.xlabel('Period (Years)')\n",
    "plt.ylabel('Power Spectral Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a few observations:  First, the blue curve showing the periodogram of the cycle alone has a sharp peak at the period corresponding to the 'years per cycle' determined by how many cycles were completed during the 1128 'years' of the time series.  The blue curve is also zero for most of the other periods.  But note that while the peak is sharp at the expected period, it isn't zero on either side of that peak -- there are 'lobes' of spurious variance that have leaked out of the true period.  This is one of the limitations of the periodogram but also generally a challenge to spectral analysis, and we'll talk about this in lecture. \n",
    "\n",
    "The red curve with the cycle and noise combined as some different features.  There is still a peak at the appropriate period and some leakage to either side, but now the signal peak is smaller (has less variance or power density).  Also because of the presense of the noise, the shorter end of the spectrum also shows various peaks ... peaks in the spectrum which are NOT reflective of a cyclical component.  Thus when dealing with real time series, be wary -- it is possible that many spurious peaks can be observed in a periodogram simply because of the presense of Gaussian noise.  \n",
    "\n",
    "Take some time and play with the curve generation, the cycle lengths, and the noise and signal magnitudes, and then we'll move onto another time series and some additional methods we can use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sierra Nevada Precipitation \n",
    "\n",
    "We're going to be looking at data from [Williams et al. 2021](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020WR028599). In this paper, we used observational and tree-ring reconstruction the Standardized Precipition Index (SPI) for the Sierra Nevada to investigate whether there were regular cycles in California winter precipitation that might provide predictability.  We'll mostly focus here on the observed November through March SPI data, which cover the period from 1902 to 2020. \n",
    "\n",
    "Let's read the data into a DataFrame and then plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SPI_recon_NDJFM_SierraNevada.csv'\n",
    "\n",
    "# read in the CSV file and make the 0th column (the years) the index\n",
    "df = pd.read_csv(filename,index_col=0) \n",
    "\n",
    "# separate the DataFrame into separate Series \n",
    "reconstructed = df['reconstructed'].dropna() # split out the reconstructed values, dropping NaNs\n",
    "observed = df['observed'].dropna() # split out the observed values, dropping NaNs\n",
    "\n",
    "plt.plot(reconstructed,'k')\n",
    "plt.plot(observed,'r')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SPI')\n",
    "plt.title('SIERRA NEVADA WINTER SPI (Williams et al. 2021)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the periodogram first to look for possible cyclical behavior in winter SPI in the Sierra Nevada observational record.  Once again, we'll pad FFT length to the next power of and using the Hanning window from above. We'll then plot the spectrum and highlight two of the potential oscillatory modes we focused on in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the next power of 2 to pass to the periodogram for padding\n",
    "nfft = 2**math.ceil(math.log2(np.size(observed)))\n",
    "\n",
    "# calculate the simple periodogram \n",
    "f, Pxx = periodogram(observed, window=window, nfft=nfft,scaling='spectrum')\n",
    "\n",
    "# there will be power at the 0 frequency, which is hard to interpret and creates problems converting to periods, so remove it\n",
    "f = f[1:]  \n",
    "Pxx = Pxx[1:]        \n",
    "\n",
    "# Convert frequency to period  \n",
    "periods = 1 / f  # Divide 1 by the frequency vector to get a period vector\n",
    "important_periods = [2.2, 14] # a couple 'cycles per time' from Williams et al. 2021 we'll use to plot\n",
    "\n",
    "# Plot the periodogram with period (years) on the x-axis\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(periods, Pxx,'r',label=\"Cycle + Noise\")  \n",
    "plt.xscale(\"log\")\n",
    "\n",
    "# make the x-axis in 'normal' units (not scientific notation)\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())  # Use scalar formatter to allow us to avoid scientific notation\n",
    "plt.gca().ticklabel_format(style='plain', axis='x')  \n",
    "\n",
    "custom_ticks = [2, 2.5, 3.3, 5, 10, 20, 50, 100]  # Periods to label\n",
    "plt.xticks(custom_ticks)\n",
    "plt.xlim([1.9,110])\n",
    "plt.xlabel('Period (years/cycle)')\n",
    "plt.ylabel('Power Spectral Density')\n",
    "\n",
    "# mark the important periods from Williams et al. 2021\n",
    "for period in important_periods:\n",
    "    plt.axvline(x=period, color='lightblue', linestyle='--', alpha=0.75)\n",
    "    plt.text(period, max(Pxx)*0.8, f'{period} years', color='lightblue', rotation=-45, verticalalignment='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are two clear peaks at ~2.2 years and between 13 and 15 years.   However, you'll also see that the spectrum is quite noisy, with multiple smaller peaks between 4 and 6 years. \n",
    "\n",
    "One thing you can do with periodogram spectra is smooth them directly.  This is quite often done with a Daniell filter, which is very similar to a moving average.  You can specify the span of the filter (the width) and the smoothing is accomplished by convolution of the filter (or kernel) and the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Daniell filter (moving average) for additional smoothing\n",
    "def daniell_filter(data, width):\n",
    "    kernel = np.ones(width) / width  # build the moving average kernel\n",
    "    return np.convolve(data, kernel, mode='same') # convolve the filter\n",
    "\n",
    "Pxx_smoothed = daniell_filter(Pxx,3)\n",
    "Pxx_smoothed_more = daniell_filter(Pxx,5)\n",
    "\n",
    "# Plot the periodogram with period (years) on the x-axis\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(periods, Pxx, color='pink', label=\"Periodogram\", marker='o')  # Plot dots for the pink line\n",
    "plt.plot(periods, Pxx_smoothed, color='red', label=\"Periodogram + Daniell Smoothing (3)\")  # Red line for the smoothed periodogram\n",
    "plt.plot(periods, Pxx_smoothed_more, color='darkred', label=\"Periodogram + Daniell Smoothing (5)\")  # Red line for the smoothed periodogram\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "# make the x-axis in normal units\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())  # Use scalar formatter to avoid scientific notation\n",
    "plt.gca().ticklabel_format(style='plain', axis='x')  \n",
    "\n",
    "custom_ticks = [2, 2.5, 3.3, 5, 10, 20, 50, 100]  # Example periods to label\n",
    "plt.xticks(custom_ticks)\n",
    "plt.xlim([1.9,110])\n",
    "plt.xlabel('Period (years/cycle)')\n",
    "plt.ylabel('Power Spectral Density')\n",
    "\n",
    "for period in important_periods:\n",
    "    plt.axvline(x=period, color='lightblue', linestyle='--', alpha=0.75)\n",
    "    plt.text(period, max(Pxx)*0.8, f'{period} years', color='lightblue', rotation=-45, verticalalignment='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of smoothing is somewhat arbitrary and depending on application, desired spectral resolution (or bandwidth), and a priori knowledge of your system.  You can see that the Daniell filter applied to the noisy periodogram spectrum of the observed Sierra Nevada SPI smooths out the features near 5 years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothed Periodogram from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to spectral analysis is the Blackman-Tukey smoothed periodogram.  The primary benefit these days is that it gives you a smoother spectrum (but for a different reason than the Daniell post hoc filtering).  The Blackman-Tukey method starts from the autocovariance of the time signal itself, applying a window (often a Hann or Tukey window) to the autocovariance function.  The Discrete Fourier Transform (DFT) is then perform on that windowed autocorrelation function.  The result is a smoother version of the periodogram with reduced variance compared to that calculated directly, because the DFT is performed on the windowed autocovariance of the time series.  This comes at the expense of the spectral resolution, but can be desireable for reducing the influence of potential random fluctuations. \n",
    "\n",
    "There is no built-in function of the Blackman-Tukey smoothed periodogram in Python that I am aware of.  Here, I've attempted to build a function based on how MATLAB [does this](https://www.mathworks.com/help/ident/ref/spa.html).  See [here](https://www.mit.bme.hu/eng/system/files/oktatas/targyak/9132/Ljung_L_System_Identification_Theory_for_User-ed2.pdf) as well.  It is very possible this is not the most efficient or Pythonic way to do this, but I can reproduce fairly closely the results I get in MATLAB with the Python code I've written below, so this will do for now:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import fft, ifft  # we'll use Numpy's fft in the function\n",
    "\n",
    "def autocovariance(data, M):\n",
    "   # Calculate the autocovariance values for lags 0 to M-1, this is directly mimicking MATLAB's covf function\n",
    "\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    autocov = np.zeros(M) # pre-allocate return array\n",
    "    \n",
    "    for lag in range(M): # mimic how MATLAB does it, although probably more efficient ways to do this! \n",
    "        autocov[lag] = np.dot(data[:n-lag] - mean, data[lag:] - mean) / n\n",
    "    \n",
    "    return autocov\n",
    "\n",
    "def hann_window(M):\n",
    "    # This mimics how MATLAB does it, which is slightly different that Scipy's Hann window\n",
    "    return 0.5 * (1 + np.cos(np.pi * np.arange(M) / (M - 1)))\n",
    "\n",
    "def blackman_tukey_spectrum(data, M, fs=1):\n",
    "    #  This performs the core of the Blackman-Tukey spectral estimation.\n",
    "\n",
    "    # First, call the function above to calculate the lagged autocovariance \n",
    "    R = autocovariance(data, M)\n",
    "    \n",
    "    # Now, create and apply the Hann window to the autocovariance array, using the function above\n",
    "    window = hann_window(M)\n",
    "    R_windowed = R * window\n",
    "    \n",
    "    # calculate the next-power-of-2 and pad the windowed autocorrelation array\n",
    "    nfft = 2 ** int(np.ceil(np.log2(2 * M)))  # next power of 2 \n",
    "    R_padded = np.concatenate([R_windowed, np.zeros(nfft - M)]) # add the padding to the end\n",
    "    \n",
    "    # compute the FFT of the windowed autocovariance, and keep the real and positive parts only \n",
    "    spectrum_full = np.real(fft(R_padded))  \n",
    "    spectrum = spectrum_full[:nfft // 2]\n",
    "    \n",
    "    # get the corresponding frequency values\n",
    "    freqs = np.fft.fftfreq(nfft, fs)[:nfft // 2]\n",
    "    \n",
    "    return spectrum, freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our new Blackman-Tukey function to the observed SPI data again.  One of the most important parameters is the window lag, $M$, and the choice will (as with many things in spectral analysis) reflect a balance between spectral resolution and variance.  A smaller $M$ will give a smoother spectrum with smaller variance, while a larger $M$ will reveal more and narrowed spectral peaks but generally a noisier periodogram.  The rule of thumb I learned was that $M$ should ideally fall between 1/3rd to 1/20th of the time series length, but other lengths are allowed. \n",
    "\n",
    "We'll start with $M=40$, but I encourage you to experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(observed)\n",
    "M = 40\n",
    "fs=1\n",
    "\n",
    "# call my Blackman-Tukey function above\n",
    "Pxxbt, fbt = blackman_tukey_spectrum(observed, M, fs)\n",
    "Pxxbt, fbt = Pxxbt[1:], fbt[1:]\n",
    "\n",
    "# figure with 2 panel to compare the two spectra\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# First subplot\n",
    "ax1.plot(1/f, Pxx, 'r')  # Plot for the first periodogram\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Period (years/cycle)')\n",
    "ax1.set_ylabel('Power Spectral Density')\n",
    "ax1.xaxis.set_major_formatter(ScalarFormatter())  # Use scalar formatter for x-axis\n",
    "ax1.ticklabel_format(style='plain', axis='x')  # Ensure no scientific notation\n",
    "ax1.set_xticks([2, 2.5, 3.3, 5, 10, 20, 50, 100])  # Custom ticks\n",
    "ax1.grid(\"both\")\n",
    "ax1.set_title('Periodogram')\n",
    "for period in important_periods:\n",
    "    ax1.axvline(x=period, color='lightblue', linestyle='--', alpha=0.75)\n",
    "    ax1.text(period, max(Pxx)*0.8, f'{period} years', color='lightblue', rotation=-45, verticalalignment='center')\n",
    "    \n",
    "# Second subplot\n",
    "ax2.plot(1/fbt, Pxxbt, 'r')  # Plot for the second periodogram\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Period (years/cycle)')\n",
    "ax2.set_ylabel('Power Spectral Density')\n",
    "ax2.xaxis.set_major_formatter(ScalarFormatter())  # Use scalar formatter for x-axis\n",
    "ax2.ticklabel_format(style='plain', axis='x')  # Ensure no scientific notation\n",
    "ax2.set_xticks([2, 2.5, 3.3, 5, 10, 20, 50, 100])  # Custom ticks\n",
    "ax2.grid(\"both\")\n",
    "ax2.set_title('Blackman-Tukey Smoothed Periodogram')\n",
    "for period in important_periods:\n",
    "    ax2.axvline(x=period, color='lightblue', linestyle='--', alpha=0.90)\n",
    "    ax2.text(period, max(Pxxbt)*0.8, f'{period} years', color='lightblue', rotation=-45, verticalalignment='center')\n",
    "    \n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some observations about the Blackman-Tukey spectra as a function of different $M$.  How might the use of this particular approach to spectral analysis influence your investigation into cyclicity in California winter precipitation over the last several centuries? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "1. Apply spectral analysis to the reconstructed SPI series - how does it differ from the observed?  How do different choices, especially with respect to the Blackman-Tukey method and use of the Daniell filter affect your interpretation of the spectra? \n",
    "2. Explore additional spectral analysis tools - specifcally, please look at and try to use the [Welch method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch)\n",
    "3. Why might you need to use the [Lomb-Scargle method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lombscargle.html#scipy.signal.lombscargle).  In general, what is one of the major assumptions of the type of time series analysis we've done thus far? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
